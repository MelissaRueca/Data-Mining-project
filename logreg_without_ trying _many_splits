from sklearn.pipeline import Pipeline
from sklearn.model_selection import StratifiedKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegressionCV, LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import numpy as np
import os
import pandas as pd
import re
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Download required NLTK data
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('punkt_tab', quiet=True) 

# Load reviews
def load_reviews(path, label):
    """
    Load reviews from fold directories and assign labels.
    """
    data = []
    for fold in range(1,6):
        folder = path + f"/fold{fold}"
        for file in os.listdir(folder):
            with open(os.path.join(folder, file), "r", encoding="utf-8") as f:
                text = f.read().strip()
                data.append({
                    "text": text,
                    "label": label,
                    "fold": fold
                })
    return pd.DataFrame(data)

# Load and merge datasets 
truthful_df = load_reviews("negative_polarity/truthful_from_Web", "truthful") 
deceptive_df = load_reviews("negative_polarity/deceptive_from_MTurk", "deceptive") 
df = pd.concat([truthful_df, deceptive_df], ignore_index=True) 

# Keep negations
stop_words = set(stopwords.words('english')) 
stop_words.discard('not') 
stop_words.discard('no')
stop_words.discard("n't") 

lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    """
    Preprocessing Text :
    1. Convert to Lowercase
    2. Removes HTML tags
    3. Removes punctuation and digits
    4. Tokenization
    5. Stopword removal (keeping negations)
    6. Lemmatization
    """
    text = text.lower()
    text = re.sub(r'<.*?>', '', text)
    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))
    tokens = nltk.word_tokenize(text)
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return " ".join(tokens)

# Apply preprocessing 
df["clean_text"] = df["text"].apply(preprocess_text)

# Split folds 1-4 for training and fold 5 for testing
train_df = df[df["fold"] != 5]
test_df = df[df["fold"] == 5]

# Extract labels
y_train = train_df["label"]
y_test = test_df["label"]


def plot_confusion_matrix(y_true, y_pred, labels=("truthful", "deceptive"), model_name="Logistic Regression", ngram_label="Unigram"):
    """
    Display a count-based confusion matrix with a clear title like:
    'Logistic Regression - Unigram' or 'Logistic Regression - Unigram+Bigram'.
    """
    cm = confusion_matrix(y_true, y_pred, labels=list(labels))

    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
                xticklabels=labels, yticklabels=labels, cbar=False)

    plt.title(f"{model_name} - {ngram_label}", fontsize=13, fontweight="bold")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.tight_layout()
    plt.show()


def logistic_regression_pipeline(train_text, train_y, test_text, test_y, ngram_range=(1,1), name="Unigrams"):
    print(f"\n--- {name} (ngrams={ngram_range}) ---")

    # We'll use 4-fold cross-validation on the training set to tune the model
    inner_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

    # The pipeline handles text vectorization and model training together
    pipe = Pipeline([
        ("tfidf", TfidfVectorizer(
            max_df=0.95,
            min_df=2,
            ngram_range=ngram_range,
            max_features=1000,
            lowercase=False
        )),
        ("lr", LogisticRegressionCV(
            Cs=np.logspace(-1, 1, 5),     # Try different C values between 0.1 and 10
            cv=inner_cv,
            penalty="l1",
            solver="liblinear",        
            scoring="accuracy",                 
            max_iter=5000,
            n_jobs=-1,
            refit=True,                   # retrain on all training data after CV
            random_state=42
        ))
    ])

    # Train the model (TF-IDF + Logistic Regression) using folds 1–4
    pipe.fit(train_text, train_y)

    # Show the C value the model chose during cross-validation
    chosen_C = pipe.named_steps["lr"].C_
    print("Best C value found:", chosen_C)

    # Test the model on fold 5 (which was never seen before)
    y_pred = pipe.predict(test_text)
    acc = accuracy_score(test_y, y_pred)
    print("Test Accuracy:", round(acc, 4))
    print("\nClassification Report:\n", classification_report(test_y, y_pred))
    print("Confusion Matrix:\n", confusion_matrix(test_y, y_pred))

    ngram_label = "Unigram" if ngram_range == (1,1) else "Unigram+Bigram"
    plot_confusion_matrix(test_y, y_pred,labels=("truthful", "deceptive"),
                           model_name="Logistic Regression",ngram_label=ngram_label)


    # # Just to double-check: train a final model manually with the best C
    # best_C = float(np.ravel(chosen_C)[0])
    # tfidf_final = TfidfVectorizer(
    #     max_df=0.95, min_df=2, ngram_range=ngram_range, lowercase=False
    # )
    # X_train_final = tfidf_final.fit_transform(train_text)
    # X_test_final = tfidf_final.transform(test_text)

    # final_model = LogisticRegression(
    #     penalty="l1", C=best_C, solver="liblinear", max_iter=5000, random_state=42
    # )
    # final_model.fit(X_train_final, train_y)
    # y_pred_final = final_model.predict(X_test_final)
    # acc_final = accuracy_score(test_y, y_pred_final)
    # print(f"\n(Sanity Check) Accuracy after refitting manually: {acc_final:.4f}")

    return acc, chosen_C, pipe


# Run the function for unigrams
acc_uni, C_uni, pipe_uni = logistic_regression_pipeline(
    train_df["clean_text"], y_train,
    test_df["clean_text"], y_test,
    ngram_range=(1,1),
    name="Unigram TF-IDF"
)

# Run the function for unigrams + bigrams
acc_bi, C_bi, pipe_bi = logistic_regression_pipeline(
    train_df["clean_text"], y_train,
    test_df["clean_text"], y_test,
    ngram_range=(1,2),
    name="Unigram+Bigram TF-IDF"
)

print("\n--- Final Comparison ---")
print(f"Unigram accuracy        : {acc_uni:.4f}")
print(f"Unigram + Bigram accuracy: {acc_bi:.4f}")


import numpy as np
import pandas as pd

def show_top_terms(pipe, class_labels=("truthful", "deceptive"), top_n=5):
    """
    Show the top-n most predictive terms for each class
    based on Logistic Regression coefficients.
    """
    vectorizer = pipe.named_steps["tfidf"]
    model = pipe.named_steps["lr"]

    feature_names = np.array(vectorizer.get_feature_names_out())
    coefs = model.coef_[0]  # single array for binary classification

    # Larger positive weights → more likely 'deceptive'
    # Larger negative weights → more likely 'truthful'
    top_fake_idx = np.argsort(coefs)[-top_n:][::-1]
    top_real_idx = np.argsort(coefs)[:top_n]

    print(f"\nTop {top_n} terms pointing to FAKE (deceptive) reviews:")
    for i in top_fake_idx:
        print(f"{feature_names[i]:<20} {coefs[i]:.4f}")

    print(f"\nTop {top_n} terms pointing to GENUINE (truthful) reviews:")
    for i in top_real_idx:
        print(f"{feature_names[i]:<20} {coefs[i]:.4f}")

    # Optional: return as DataFrame for inspection
    data = {
        "term": feature_names,
        "coef": coefs
    }
    return pd.DataFrame(data).sort_values("coef", ascending=False)

show_top_terms(pipe_uni, top_n=5)
show_top_terms(pipe_bi, top_n=5)