import os
import pandas as pd
import re
import string
import pickle
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Download required NLTK data
nltk.download('stopwords', quiet=True)
nltk.download('wordnet', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('punkt_tab', quiet=True) 

# Load reviews
def load_reviews(path, label):
    """
    Load reviews from fold directories and assign labels.
    """
    data = []
    for fold in range(1,6):
        folder = path + f"/fold{fold}"
        for file in os.listdir(folder):
            with open(os.path.join(folder, file), "r", encoding="utf-8") as f:
                text = f.read().strip()
                data.append({
                    "text": text,
                    "label": label,
                    "fold": fold
                })
    return pd.DataFrame(data)

# Load and merge datasets 
truthful_df = load_reviews("negative_polarity/truthful_from_Web", "truthful") 
deceptive_df = load_reviews("negative_polarity/deceptive_from_MTurk", "deceptive") 
df = pd.concat([truthful_df, deceptive_df], ignore_index=True) 

# Keep negations
stop_words = set(stopwords.words('english')) 
stop_words.discard('not') 
stop_words.discard('no')
stop_words.discard("n't") 

lemmatizer = WordNetLemmatizer()

def preprocess_text(text):
    """
    Preprocessing Text :
    1. Convert to Lowercase
    2. Removes HTML tags
    3. Removes punctuation and digits
    4. Tokenization
    5. Stopword removal (keeping negations)
    6. Lemmatization
    """
    text = text.lower()
    text = re.sub(r'<.*?>', '', text)
    text = text.translate(str.maketrans('', '', string.punctuation + string.digits))
    tokens = nltk.word_tokenize(text)
    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]
    return " ".join(tokens)

# Apply preprocessing 
df["clean_text"] = df["text"].apply(preprocess_text)

# Split folds 1-4 for training and fold 5 for testing
train_df = df[df["fold"] != 5]
test_df = df[df["fold"] == 5]

# Extract labels
y_train = train_df["label"]
y_test = test_df["label"]

# Feature extraction

# Unigrams (single words)
tfidf_uni = TfidfVectorizer(
        max_df=0.95,  # exclude terms that appear in >95% of documents
        min_df=2, # exclude terms that appear <2 documents
        ngram_range=(1,1), 
        lowercase=False  
)

X_train_uni = tfidf_uni.fit_transform(train_df["clean_text"])
X_test_uni= tfidf_uni.transform(test_df["clean_text"]) 

# Unigrams + bigrams (single + two-word phrases)
tfidf_bi = TfidfVectorizer(
        max_df=0.95,
        min_df=2,
        ngram_range=(1, 2),
        lowercase=False
)

X_train_bi = tfidf_bi.fit_transform(train_df["clean_text"])
X_test_bi = tfidf_bi.transform(test_df["clean_text"])

# Save processed data
df.to_csv("processed_reviews.csv", index=False) 
train_df.to_csv("train_reviews.csv", index=False)
test_df.to_csv("test_reviews.csv", index=False)

# Save vectorizers 
with open("tfidf_uni.pkl", "wb") as f:
    pickle.dump(tfidf_uni, f)
with open("tfidf_bi.pkl", "wb") as f:
    pickle.dump(tfidf_bi, f)

print("Data preprocessing complete.")


# ==== START: Modeling & Evaluation (drop-in) ====
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix
import pickle

def plot_confusion(y_true, y_pred, title, save_path=None):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(4,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['truthful (0)', 'deceptive (1)'],
                yticklabels=['truthful (0)', 'deceptive (1)'])
    plt.xlabel('Predicted')
    plt.ylabel('True')
    plt.title(title)
    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=150)
    plt.show()

def run_experiment(ngram_range=(1,1), use_tfidf=True, n_splits=4, tag=''):
    # Map your string labels to ints: deceptive=1, truthful=0
    y_train_bin = (y_train == 'deceptive').astype(int).to_numpy()
    y_test_bin  = (y_test  == 'deceptive').astype(int).to_numpy()

    vect_cls = TfidfVectorizer if use_tfidf else CountVectorizer
    pipeline = Pipeline([
        ('vect', vect_cls(ngram_range=ngram_range, lowercase=False)),  # keep your pre-lowercasing
        ('clf', LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000))
    ])

    # Grid: vocabulary cap + regularization strength
    param_grid = {
        'vect__max_features': [500, 1000, 2000, 3000, 3500, 4000],
        'clf__C': [0.001, 0.01, 0.1, 1, 10],
    }

    cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
    grid = GridSearchCV(pipeline, param_grid, cv=cv, scoring='f1', n_jobs=-1, verbose=1)
    grid.fit(train_df["clean_text"], y_train_bin)

    print(f"\n[{tag}] ngram_range={ngram_range}, vect={'TFIDF' if use_tfidf else 'COUNT'}")
    print("Best params:", grid.best_params_)
    print(f"Best mean CV F1: {grid.best_score_:.4f}")

    best_model = grid.best_estimator_
    y_pred = best_model.predict(test_df["clean_text"])

    print("\nTest set (fold 5) classification report:")
    print(classification_report(y_test_bin, y_pred, digits=4))

    title = f"Confusion Matrix | {'TFIDF' if use_tfidf else 'COUNT'} | ngram={ngram_range} | splits={n_splits}"
    fname = f"confmat_{'tfidf' if use_tfidf else 'count'}_{ngram_range[0]}_{ngram_range[1]}_{n_splits}.png"
    plot_confusion(y_test_bin, y_pred, title, save_path=fname)

    # Feature inspection (works for linear models)
    vect = best_model.named_steps['vect']
    clf  = best_model.named_steps['clf']
    feature_names = np.array(vect.get_feature_names_out())
    coefs = clf.coef_[0]  # positive -> deceptive(1), negative -> truthful(0)

    top_deceptive_idx = np.argsort(coefs)[-10:][::-1]
    top_truthful_idx  = np.argsort(coefs)[:10]

    print("\nTop deceptive-indicative terms:")
    print(list(zip(feature_names[top_deceptive_idx], coefs[top_deceptive_idx])))

    print("\nTop truthful-indicative terms:")
    print(list(zip(feature_names[top_truthful_idx], coefs[top_truthful_idx])))

    # Save the whole pipeline (vectorizer + model)
    with open(f"best_pipeline_{'tfidf' if use_tfidf else 'count'}_{ngram_range[0]}_{ngram_range[1]}.pkl", "wb") as f:
        pickle.dump(best_model, f)

# Run the four setups (like the other script)
run_experiment((1,1), use_tfidf=False, n_splits=4, tag='Count Unigram')
run_experiment((1,2), use_tfidf=False, n_splits=4, tag='Count Uni+Bi')
run_experiment((1,1), use_tfidf=True,  n_splits=4, tag='TFIDF Unigram')
run_experiment((1,2), use_tfidf=True,  n_splits=4, tag='TFIDF Uni+Bi')

print("Modeling complete.")
# ==== END: Modeling & Evaluation ====
